{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0402d428",
   "metadata": {},
   "source": [
    "```{include} ../math-definitions.md\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898c800e",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from statsmodels.formula.api import ols\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use('seaborn-talk')\n",
    "\n",
    "\n",
    "# Valores críticos de Perron\n",
    "perronModelA = pd.DataFrame({\n",
    "    '1%':[-4.30, -4.39, -4.39, -4.34, -4.32, -4.45, -4.42, -4.33, -4.27],\n",
    "    '2.5%':[-3.93, -4.08, -4.03, -4.01, -4.01, -4.09, -4.07, -3.99, -3.97],\n",
    "    '5%': [-3.68, -3.77, -3.76, -3.72, -3.76, -3.76, -3.80, -3.75, -3.69],\n",
    "    '10%':[-3.40, -3.47, -3.46, -3.44, -3.46, -3.47, -3.51, -3.46, -3.38],\n",
    "    '90%':[-1.38, -1.45, -1.43, -1.26, -1.17, -1.28, -1.42, -1.46, -1.37],\n",
    "    '95%':[-1.09, -1.14, -1.13, -0.88, -0.79, -0.92, -1.10, -1.13, -1.04],\n",
    "    '97.5%':[-0.78, -0.90, -0.83, -0.55, -0.49, -0.60, -0.82, -0.89, -0.74],\n",
    "    '99%':[-0.46, -0.54, -0.51, -0.21, -0.15, -0.26, -0.50, -0.57, -0.47]},\n",
    "    index = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9])\n",
    "\n",
    "perronModelB = pd.DataFrame({\n",
    "    '1%':[ -4.27, -4.41, -4.51, -4.55, -4.56, -4.57, -4.51, -4.38, -4.26],\n",
    "    '2.5%':[ -3.94, -4.08, -4.17, -4.20, -4.26, -4.20, -4.13, -4.07, -3.96],\n",
    "    '5%':[ -3.65, -3.80, -3.87, -3.94, -3.96, -3.95, -3.85, -3.82, -3.68],\n",
    "    '10%':[ -3.36, -3.49, -3.58, -3.66, -3.68, -3.66, -3.57, -3.50, -3.35],\n",
    "    '90%':[ -1.35, -1.48, -1.59, -1.69, -1.74, -1.71, -1.61, -1.49, -1.34],\n",
    "    '95%':[ -1.04, -1.18, -1.27, -1.37, -1.40, -1.36, -1.28, -1.16, -1.04],\n",
    "    '97.5%':[ -0.78, -0.87, -0.97, -1.11, -1.18, -1.11, -0.97, -0.87, -0.77],\n",
    "    '99%':[ -0.40, -0.52, -0.69, -0.75, -0.82, -0.78, -0.67, -0.54, -0.43]},\n",
    "    index = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9])\n",
    "\n",
    "perronModelC = pd.DataFrame({\n",
    "    '1%':[-4.38, -4.65, -4.78, -4.81, -4.90, -4.88, -4.75, -4.70, -4.41],\n",
    "    '2.5%':[-4.01, -4.32, -4.46, -4.48, -4.53, -4.49, -4.44, -4.31, -4.10],\n",
    "    '5%':[-3.75, -3.99, -4.17, -4.22, -4.24, -4.24, -4.18, -4.04, -3.80],\n",
    "    '10%':[-3.45, -3.66, -3.87, -3.95, -3.96, -3.95, -3.86, -3.69, -3.46],\n",
    "    '90%':[-1.44, -1.60, -1.78, -1.91, -1.96, -1.93, -1.81, -1.63, -1.44],\n",
    "    '95%':[-1.11, -1.27, -1.46, -1.62, -1.69, -1.63, -1.47, -1.29, -1.12],\n",
    "    '97.5%':[-0.82, -0.98, -1.15, -1.35, -1.43, -1.37, -1.17, -1.04, -0.80],\n",
    "    '99%':[-0.45, -0.67, -0.81, -1.04, -1.07, -1.08, -0.79, -0.64, -0.50]},\n",
    "    index = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874edbaf",
   "metadata": {},
   "source": [
    "# Cambio estructural y raíces unitarias: fecha conocida\n",
    "\n",
    "\n",
    "\n",
    "## Cambio estructural y raíces unitarias\n",
    "\n",
    "Cuando se realizan pruebas de raíz unitaria, debe tenerse cuidado si se sospecha que ha ocurrido un cambio estructural.\n",
    "\n",
    "Cuando hay cambios estructurales, los estadísticos Dickey-Fuller están sesgados hacia no rechazar la hipótesis de que hay raíz unitaria.\n",
    "\n",
    "\n",
    "\n",
    "## Ejemplos de cambios estructurales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14032568",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "np.random.seed(2020)\n",
    "\n",
    "T = 100\n",
    "data2 = pd.DataFrame({'t':np.arange(T), 'e':0.5*np.random.randn(T),'y0':0.0, 'y1':0.0})\n",
    "data2['DL'] = 3*(data2['t']>=T/2).astype(int)\n",
    "data2['DP'] = 5*(data2['t']==int(T/2)).astype(int)\n",
    "\n",
    "for t in range(1,T):\n",
    "    data2.loc[t,'y0'] = 0.5 * data2.loc[t-1,'y0'] + data2.loc[t,'e'] + data2.loc[t,'DL']\n",
    "    data2.loc[t,'y1'] = data2.loc[t-1,'y1'] + data2.loc[t,'e'] + data2.loc[t,'DP']\n",
    "\n",
    "fig, axs = plt.subplots(2,1, sharex=True)\n",
    "axs = data2[['y0', 'y1']].plot(subplots=True, ax=axs, legend=False)\n",
    "for ax in axs:\n",
    "    ax.axvline(T/2, ls=':', color='gray')\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "\n",
    "axs[0].set(title='$y_t = 0.5y_{t-1} + \\epsilon_t + D_L(50)$')    \n",
    "axs[1].set(title='$y_t = y_{t-1} + \\epsilon_t + D_P(50)$')    \n",
    "\n",
    "axs[0].annotate('A',[0.05,0.9], xycoords='axes fraction', size=26, color='red')\n",
    "axs[1].annotate('B',[0.05,0.9], xycoords='axes fraction', size=26, color='red')\n",
    "\n",
    "sns.regplot(x='t',y='y0', data=data2, ax=axs[0], color='C0')\n",
    "sns.regplot(x='t',y='y1', data=data2, ax=axs[1], color='C1');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a9853a",
   "metadata": {},
   "source": [
    "Los datos de la figura {badge}`A, badge-danger` fueron generados por\n",
    "\\begin{align*}\n",
    "y_t       &= 0.5y_{t-1} + \\epsilon_{t} + 3D_L(50)_t \\tag{AR(1) + cambio $\\mu$}\\\\\n",
    "D_L(50)_t &= \\mathrm{I}(t\\geq 50) \\tag{dummy de nivel}\n",
    "\\end{align*}\n",
    "\n",
    "La serie simulada parece tener una tendencia lineal.\n",
    "La manera apropiada de estimar este modelo es\n",
    "\\begin{equation*}\n",
    "y_t = \\beta_0 + \\beta_1y_{t-1} + \\delta D_L(50) + \\epsilon_{t}\n",
    "\\end{equation*}\n",
    "\n",
    "pero si estimamos\n",
    "\n",
    "\\begin{equation*}\n",
    "y_t = \\alpha_0 + \\alpha_1 t + \\epsilon_{t}\n",
    "\\end{equation*}\n",
    "\n",
    "el coeficiente $\\alpha_1$ tendería a ser positivo para capturar el salto en la serie.\n",
    "\n",
    "\n",
    "Suponga que por equivocación estimamos\n",
    "\\begin{equation*}\n",
    "y_t - y_{t-1} = c + \\gamma y_{t-1} + \\epsilon_{t}\n",
    "\\end{equation*}\n",
    "lo que sería una caminata aleatoria con deriva si $\\gamma = 0$. Entonces:\n",
    "\\begin{equation*}\n",
    "y_t = y_0 + ct + \\sum_{i=i}^{t}\\epsilon_{i}\n",
    "\\end{equation*}\n",
    "\n",
    "Esta ecuación describe los datos de manera similar a como lo hace $y_t = \\alpha_0 + \\alpha_1 t + \\epsilon_{t}$, lo cual nos dice que la regresión Dickey-Fuller sesgaría los resultados hacia $\\gamma = 0$, es decir, hacia no rechazar la presencia de una raíz unitaria.\n",
    "\n",
    "Perron (1989) demostró este sesgo con simulaciones de Monte Carlo.\n",
    "\n",
    "\n",
    "Ahora bien, una serie con raíz unitaria también puede presentar un cambio estructural, como en la figura {badge}`B, badge-danger`, generada por\n",
    "\\begin{align*}\n",
    "y_t &= y_{t-1} + \\epsilon_{t} + 5D_P(50)_t \\tag{RW + cambio $\\mu$}\\\\\n",
    "D_P(50)_t &= \\mathrm{I}(t = 50) \\tag{dummy de impulso}\n",
    "\\end{align*}\n",
    "\n",
    "Note que $D_P(t)$ es igual a 1 solo en el período $t$: cualquier cambio aditivo a una caminata aleatoria tiene un efecto permanente sobre el nivel de la serie.\n",
    "\n",
    "La serie simulada parece tener una tendencia lineal.\n",
    "De hecho, no es sencillo distinguirla de la figura **A** a simple vista.\n",
    "\n",
    "\n",
    "## ¿Cómo saber entonces si una serie con cambio estructural tiene raíz unitaria?\n",
    "\n",
    "Una opción, similar a lo que hace la prueba de Chow, es partir la muestra de datos en dos partes, y realizar pruebas de raíz unitaria en cada una por separado\n",
    "Lo malo de este procedimiento es que pierde muchos grados de libertad.\n",
    "Sería preferible tener un test que utilice toda la muestra\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## ¿Caminata aleatoria o serie estacionaria alrededor de tendencia?\n",
    "\n",
    "\\textcite{Perron1989} desarrolla un procedimiento formal para detectar raíces unitarias en presencia de un cambio estructural ocurrido en $t=\\tau$.\n",
    "\n",
    "Las hipótesis nula y alternativa son\n",
    "\\begin{align*}\n",
    "y_t &= \\alpha_0 + y_{t-1} + \\mu_1 D^P_t(\\tau) + \\epsilon_{t} \\tag{nula}\\\\\n",
    "y_t &= \\alpha_0 + \\alpha_2 t + \\mu_2 D^L_t(\\tau) + \\epsilon_{t} \\tag{alternativa}\n",
    "\\end{align*}\n",
    "\n",
    "Es decir, la hipótesis nula es que hay un solo salto en una caminata aleatoria en el período $\\tau$, la alternativa es que en esa misma fecha hay un solo salto en el intercepto de una serie estacionaria alrededor de tendencia.\n",
    "\n",
    "\n",
    "Observemos que\n",
    "\\begin{equation*}\n",
    "\\sum_{k=1}^{t}D_p(\\tau)_k = D_L(\\tau)_t\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d088264",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "T = 7\n",
    "data3 = pd.DataFrame(index=np.arange(T))\n",
    "data3['DL'] = (data3.index>=3).astype(int)\n",
    "data3['DP'] = (data3.index==3).astype(int)\n",
    "\n",
    "fig, axs = plt.subplots(2,1,figsize=[12,4], sharex=True)\n",
    "data3.plot.bar(subplots=True, width=0.05, ax=axs, legend=False)\n",
    "data3.plot(subplots=True, ls='', marker='o', ax=axs, legend=False)\n",
    "for ax in axs:\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['bottom'].set_linewidth(0.25)\n",
    "    ax.spines['left'].set_linewidth(0.25)\n",
    "    ax.set(yticks=[0,1], ylim=[-0.08, 1.08], title='')\n",
    "\n",
    "axs[1].set_xticks(np.arange(T))\n",
    "axs[1].set_xticklabels([f'$\\\\tau {tau:+d}$' if tau else '$\\\\tau$' for tau in range(-3,4)])\n",
    "axs[0].annotate('$D_L(\\\\tau)_t$', [0.5, 0.5], size=16, color=axs[0].lines[0].get_color())\n",
    "axs[1].annotate('$D_P(\\\\tau)_t$', [0.5, 0.5], size=16, color=axs[1].lines[0].get_color());"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0154a09a",
   "metadata": {},
   "source": [
    "Integrando la hipótesis nula\n",
    "\\begin{equation*}\n",
    "y_t = y_0 + \\alpha_0 t + \\mu_1D_L(\\tau)_t + \\sum_{k=0}^{t}\\epsilon_{k}\n",
    "\\end{equation*}\n",
    "vemos que es equivalente a la alternativa excepto por las perturbaciones.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Las pruebas de cambio estructural de Perron\n",
    "\n",
    "{{ empieza_test }} Las pruebas de cambio estructural de Perron {{ fin_titulo_test }}\n",
    "{{ test_inquietud }} ¿Hay raíces unitarias en presencia de un cambio estructural en $t=\\tau$?\n",
    "{{ test_hipotesis }}\n",
    "\n",
    "{badge}`Modelo A: cambio de intercepto (crash), badge-success`\n",
    "\\begin{align*}\n",
    "y_t &= \\notationbrace{\\alpha_0 + \\mu_1 D^P_t}{intercepto} +  y_{t-1}  + \\epsilon_{t} \\tag{nula}\\\\\n",
    "y_t &= \\notationbrace{\\alpha_0 + \\mu_2 D_t^L}{intercepto} + \\alpha_2 t  + \\epsilon_{t} \\tag{alternativa}\n",
    "\\end{align*}\n",
    "\n",
    "{badge}`Modelo B: cambio de tendencia (changing growth), badge-success`\n",
    "\\begin{align*}\n",
    "y_t &= \\notationbrace{\\alpha_0 + \\mu_2 D^L_t}{intercepto} +  y_{t-1}  + \\epsilon_{t} \\tag{nula}\\\\\n",
    "y_t &= \\alpha_0 + \\notationbrace{\\alpha_2 t + \\mu_3 D^T_t}{tendencia} +  \\epsilon_{t} \\tag{alternativa}\n",
    "\\end{align*}\n",
    "donde $D^T_t(\\tau) = \\max(t-\\tau, 0)$\n",
    "\n",
    "{badge}`Modelo C: cambio de intercepto y de tendencia, badge-success`\n",
    "\\begin{align*}\n",
    "y_t &= \\notationbrace{\\alpha_0 + \\mu_1 D^P_t + \\mu_2 D^L_t}{intercepto} +  y_{t-1}  + \\epsilon_{t} \\tag{nula}\\\\\n",
    "y_t &= \\notationbrace{\\alpha_0 + \\mu_2 D_t^L}{intercepto} + \\notationbrace{\\alpha_2 t + \\mu_3 D^T_t}{tendencia} +  \\epsilon_{t} \\tag{alternativa}\n",
    "\\end{align*}\n",
    "{{ test_estadistico }}\n",
    "Para implementar la prueba de Perron se siguen 3 pasos:\n",
    "\n",
    "{badge}`Paso 1:, badge-dark` Se estima la regresión correspondiente al modelo\n",
    "\\begin{align*}\n",
    "y_t &= \\alpha_0 + \\alert{\\alpha_1}y_{t-1} + \\alpha_2 t + \\mu_1 D_t^P + \\mu_2 D_t^L  +\\epsilon_{t} \\tag{A} \\\\\n",
    "y_t &= \\alpha_0 + \\alpha_2 t + \\mu_3 D_t^T  + \\tilde{y}_{t} \\qquad\\Rightarrow\n",
    "\\tilde{y}_t = \\alert{\\alpha_1}\\tilde{y}_{t-1} + \\epsilon_{t}  \\tag{B}  \\\\\n",
    "y_t &= \\alpha_0 + \\alert{\\alpha_1}y_{t-1} + \\alpha_2 t + \\mu_1 D_t^P + \\mu_2 D_t^L + \\mu_3 D_t^L  +\\epsilon_{t} \\tag{C}\\\\\n",
    "\\end{align*}\n",
    "\n",
    "{badge}`Paso 2:, badge-dark` Si los residuos de la regresión están autocorrelacionados, se estima la regresión ampliada, agregando $p$ rezagos del cambio en la variable:\n",
    "\\begin{align*}\n",
    "\\text{A y C} &:\\sum_{i=1}^{p}\\beta_i\\Delta y_{t-1}  &\n",
    "\\text{B} &:\\sum_{i=1}^{p}\\beta_i\\Delta \\tilde{y}_{t-1}\n",
    "\\end{align*}\n",
    "\n",
    "{badge}`Paso 3:,badge-dark` Se calcula el estadístico $t$ de la hipótesis $a_1=1$:\n",
    "\\begin{equation*}\n",
    "t_{\\alpha_1} = \\frac{\\hat{\\alpha_1}-1}{s.e.(\\alpha_1)}\n",
    "\\end{equation*}\n",
    "y se compara con el valor crítico de Perron.\n",
    "{{ test_interpretacion }}\n",
    "Si el estadístico estimado es menor que el valor crítico, se rechaza la hipótesis nula.\n",
    "\n",
    "El valor crítico depende de la proporción $\\lambda$ de observaciones que corresponden al periodo anterior al quiebre estructural.\n",
    "\n",
    "**Valores críticos de Perron**\n",
    "```{tabbed} Modelo A\n",
    "| 𝜆   |    1% |   2.5% |    5% |   10% |   90% |   95% |   97.5% |   99% |\n",
    "|----:|------:|-------:|------:|------:|------:|------:|--------:|------:|\n",
    "| 0.1 | -4.30 |  -3.93 | -3.68 | -3.40 | -1.38 | -1.09 |   -0.78 | -0.46 |\n",
    "| 0.2 | -4.39 |  -4.08 | -3.77 | -3.47 | -1.45 | -1.14 |   -0.90 | -0.54 |\n",
    "| 0.3 | -4.39 |  -4.03 | -3.76 | -3.46 | -1.43 | -1.13 |   -0.83 | -0.51 |\n",
    "| 0.4 | -4.34 |  -4.01 | -3.72 | -3.44 | -1.26 | -0.88 |   -0.55 | -0.21 |\n",
    "| 0.5 | -4.32 |  -4.01 | -3.76 | -3.46 | -1.17 | -0.79 |   -0.49 | -0.15 |\n",
    "| 0.6 | -4.45 |  -4.09 | -3.76 | -3.47 | -1.28 | -0.92 |   -0.60 | -0.26 |\n",
    "| 0.7 | -4.42 |  -4.07 | -3.80 | -3.51 | -1.42 | -1.10 |   -0.82 | -0.50 |\n",
    "| 0.8 | -4.33 |  -3.99 | -3.75 | -3.46 | -1.46 | -1.13 |   -0.89 | -0.57 |\n",
    "| 0.9 | -4.27 |  -3.97 | -3.69 | -3.38 | -1.37 | -1.04 |   -0.74 | -0.47 |\n",
    "```\n",
    "\n",
    "```{tabbed} Modelo B\n",
    "| 𝜆   |    1% |   2.5% |    5% |   10% |   90% |   95% |   97.5% |   99% |\n",
    "|----:|------:|-------:|------:|------:|------:|------:|--------:|------:|\n",
    "| 0.1 | -4.27 |  -3.94 | -3.65 | -3.36 | -1.35 | -1.04 |   -0.78 | -0.40 |\n",
    "| 0.2 | -4.41 |  -4.08 | -3.80 | -3.49 | -1.48 | -1.18 |   -0.87 | -0.52 |\n",
    "| 0.3 | -4.51 |  -4.17 | -3.87 | -3.58 | -1.59 | -1.27 |   -0.97 | -0.69 |\n",
    "| 0.4 | -4.55 |  -4.20 | -3.94 | -3.66 | -1.69 | -1.37 |   -1.11 | -0.75 |\n",
    "| 0.5 | -4.56 |  -4.26 | -3.96 | -3.68 | -1.74 | -1.40 |   -1.18 | -0.82 |\n",
    "| 0.6 | -4.57 |  -4.20 | -3.95 | -3.66 | -1.71 | -1.36 |   -1.11 | -0.78 |\n",
    "| 0.7 | -4.51 |  -4.13 | -3.85 | -3.57 | -1.61 | -1.28 |   -0.97 | -0.67 |\n",
    "| 0.8 | -4.38 |  -4.07 | -3.82 | -3.50 | -1.49 | -1.16 |   -0.87 | -0.54 |\n",
    "| 0.9 | -4.26 |  -3.96 | -3.68 | -3.35 | -1.34 | -1.04 |   -0.77 | -0.43 |\n",
    "```\n",
    "\n",
    "```{tabbed} Modelo C\n",
    "| 𝜆   |    1% |   2.5% |    5% |   10% |   90% |   95% |   97.5% |   99% |\n",
    "|----:|------:|-------:|------:|------:|------:|------:|--------:|------:|\n",
    "| 0.1 | -4.38 |  -4.01 | -3.75 | -3.45 | -1.44 | -1.11 |   -0.82 | -0.45 |\n",
    "| 0.2 | -4.65 |  -4.32 | -3.99 | -3.66 | -1.60 | -1.27 |   -0.98 | -0.67 |\n",
    "| 0.3 | -4.78 |  -4.46 | -4.17 | -3.87 | -1.78 | -1.46 |   -1.15 | -0.81 |\n",
    "| 0.4 | -4.81 |  -4.48 | -4.22 | -3.95 | -1.91 | -1.62 |   -1.35 | -1.04 |\n",
    "| 0.5 | -4.90 |  -4.53 | -4.24 | -3.96 | -1.96 | -1.69 |   -1.43 | -1.07 |\n",
    "| 0.6 | -4.88 |  -4.49 | -4.24 | -3.95 | -1.93 | -1.63 |   -1.37 | -1.08 |\n",
    "| 0.7 | -4.75 |  -4.44 | -4.18 | -3.86 | -1.81 | -1.47 |   -1.17 | -0.79 |\n",
    "| 0.8 | -4.70 |  -4.31 | -4.04 | -3.69 | -1.63 | -1.29 |   -1.04 | -0.64 |\n",
    "| 0.9 | -4.41 |  -4.10 | -3.80 | -3.46 | -1.44 | -1.12 |   -0.80 | -0.50 |\n",
    "```\n",
    "Fuente: \\textcite{Perron1989}\n",
    "{{ termina_test }}\n",
    "\n",
    "\n",
    "\n",
    "{{ empieza_ejemplo }} Pruebas de cambio estructural {{ fin_titulo_ejemplo }}\n",
    "\n",
    "Perron analiza los datos de Nelson y Plosser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a6a39c",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "pd.options.plotting.backend = \"plotly\"\n",
    "\n",
    "NP = pd.read_stata('datos/NelsonPlosserData.dta', index_col='year')\n",
    "NP.index = NP.index.year\n",
    "\n",
    "# modelo de salarios nominales\n",
    "lwg = NP[['lwg']].dropna()\n",
    "lwg['DL'] = (lwg.index > 1929).astype(int)\n",
    "lwg['DP'] = (lwg.index == 1930).astype(int)\n",
    "lwg['t'] = np.arange(lwg.shape[0])\n",
    "lwg['Ly'] = lwg['lwg'].shift(1)\n",
    "model1_lwg = ols('lwg~ DL + DP + t + Ly', lwg).fit()\n",
    "model2_lwg = ols('lwg~ DL + t ', lwg).fit()\n",
    "\n",
    "lwg['Ajuste'] = model2_lwg.fittedvalues\n",
    "\n",
    "lwg[['lwg', 'Ajuste']].plot()\n",
    "\n",
    "#title='Salarios nominales'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7735a05",
   "metadata": {},
   "source": [
    "Al estimar el modelo A\n",
    "\\begin{equation*}\n",
    "y_t = \\alpha_0 + \\alpha_1y_{t-1} + \\alpha_2 t + \\mu_1 D_t^P + \\mu_2 D_t^L +\\sum_{i=1}^{p}\\beta_i\\Delta y_{t-1}  +\\epsilon_{t}\n",
    "\\end{equation*}\n",
    "\n",
    "encuentran"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c333a06a",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "def Perron_testA(serie, k=8):\n",
    "    dta = NP[[serie]].dropna()\n",
    "    dta.rename(columns={serie:'y'}, inplace=True)\n",
    "    dta['DL'] = (dta.index>1929).astype(int)\n",
    "    dta['DP'] = (dta.index==1930).astype(int)\n",
    "    dta['t'] = np.arange(dta.shape[0])\n",
    "    dta['Ly'] = dta['y'].shift(1)\n",
    "    dta['Dy'] = dta['y'].diff(1)\n",
    "    for j in range(1, k+1):\n",
    "        dta[f'D{j}y'] = dta['Dy'].shift(j)\n",
    "\n",
    "    lags = '+'.join(dta.columns[-k:])\n",
    "\n",
    "    modelo = ols('y ~ DL + DP + t + Ly + '+ lags, dta).fit()\n",
    "    tval = ((modelo.params - 1)/modelo.bse).round(2)['Ly']\n",
    "    lda = 1-dta['DL'].mean()\n",
    "    crit = perronModelA.loc[np.round(lda,1)]\n",
    "\n",
    "    return {'𝜆': np.round(lda,2), 't': tval, '1%':crit['1%'],'5%':crit['5%'],'10%':crit['10%']}\n",
    "\n",
    "variables = {'lrgnp':'Real GNP',\n",
    "           'lgnp':'Nominal GNP',\n",
    "           'lpcrgnp':'Real per capita GNP',\n",
    "           'lip':'Industrial production',\n",
    "           'lemp':'Employment',\n",
    "           'lun':'Unemployment rate',\n",
    "           'lprgnp':'GNP deflator',\n",
    "           'lcpi':'Consumer prices',\n",
    "           'lwg':'Wages',\n",
    "           'lrwg':'Real wages',\n",
    "           'lm':'Money stock',\n",
    "           'lvel':'Velocity',\n",
    "           'bnd':'Bond yield',\n",
    "           'lsp500':'Common stock prices'}\n",
    "\n",
    "seriesA = ['lrgnp', 'lgnp', 'lpcrgnp', 'lip', 'lemp', 'lprgnp', 'lcpi', 'lwg', 'lm']\n",
    "lags = [8,8,7,8,7,5,2,7,6]\n",
    "\n",
    "temp = pd.DataFrame([Perron_testA(ser, k) for ser, k in zip(seriesA, lags)], index=seriesA)\n",
    "temp.rename(index=variables).to_latex('perron-nelson-plosser.tex', escape=False)\n",
    "\n",
    "temp.rename(index=variables)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491371bb",
   "metadata": {},
   "source": [
    "{{ termina_ejemplo }}"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "md:myst",
   "text_representation": {
    "extension": ".md",
    "format_name": "myst"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "source_map": [
   30,
   37,
   81,
   98,
   126,
   203,
   224,
   340,
   361,
   372,
   419
  ],
  "substitutions": {
   "empieza_ejemplo": "<div class=\"ejemplo\">\n<div class=\"ejemplo-titulo\"><b>Ejemplo: &nbsp;\n",
   "empieza_test": "<div class=\"test\">\n<div class=\"test-titulo\">\n",
   "fin_titulo_ejemplo": "</b></div>",
   "fin_titulo_test": "</div>",
   "termina_ejemplo": "</div>",
   "termina_test": "</div>",
   "test_estadistico": "<br><hr><i class=\"fas fa-calculator test-simbolo\"></i>\n",
   "test_hipotesis": "<br><hr><i class=\"fas fa-heading test-simbolo\"></i>\n",
   "test_inquietud": "<i class=\"fas fa-question test-simbolo\"></i>\n",
   "test_interpretacion": "<br><hr><i class=\"far fa-lightbulb test-simbolo\"></i>"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}