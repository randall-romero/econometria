{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0402d428",
   "metadata": {},
   "source": [
    "```{include} ../math-definitions.md\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898c800e",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from statsmodels.formula.api import ols\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use('seaborn-talk')\n",
    "\n",
    "\n",
    "# Valores cr칤ticos de Perron\n",
    "perronModelA = pd.DataFrame({\n",
    "    '1%':[-4.30, -4.39, -4.39, -4.34, -4.32, -4.45, -4.42, -4.33, -4.27],\n",
    "    '2.5%':[-3.93, -4.08, -4.03, -4.01, -4.01, -4.09, -4.07, -3.99, -3.97],\n",
    "    '5%': [-3.68, -3.77, -3.76, -3.72, -3.76, -3.76, -3.80, -3.75, -3.69],\n",
    "    '10%':[-3.40, -3.47, -3.46, -3.44, -3.46, -3.47, -3.51, -3.46, -3.38],\n",
    "    '90%':[-1.38, -1.45, -1.43, -1.26, -1.17, -1.28, -1.42, -1.46, -1.37],\n",
    "    '95%':[-1.09, -1.14, -1.13, -0.88, -0.79, -0.92, -1.10, -1.13, -1.04],\n",
    "    '97.5%':[-0.78, -0.90, -0.83, -0.55, -0.49, -0.60, -0.82, -0.89, -0.74],\n",
    "    '99%':[-0.46, -0.54, -0.51, -0.21, -0.15, -0.26, -0.50, -0.57, -0.47]},\n",
    "    index = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9])\n",
    "\n",
    "perronModelB = pd.DataFrame({\n",
    "    '1%':[ -4.27, -4.41, -4.51, -4.55, -4.56, -4.57, -4.51, -4.38, -4.26],\n",
    "    '2.5%':[ -3.94, -4.08, -4.17, -4.20, -4.26, -4.20, -4.13, -4.07, -3.96],\n",
    "    '5%':[ -3.65, -3.80, -3.87, -3.94, -3.96, -3.95, -3.85, -3.82, -3.68],\n",
    "    '10%':[ -3.36, -3.49, -3.58, -3.66, -3.68, -3.66, -3.57, -3.50, -3.35],\n",
    "    '90%':[ -1.35, -1.48, -1.59, -1.69, -1.74, -1.71, -1.61, -1.49, -1.34],\n",
    "    '95%':[ -1.04, -1.18, -1.27, -1.37, -1.40, -1.36, -1.28, -1.16, -1.04],\n",
    "    '97.5%':[ -0.78, -0.87, -0.97, -1.11, -1.18, -1.11, -0.97, -0.87, -0.77],\n",
    "    '99%':[ -0.40, -0.52, -0.69, -0.75, -0.82, -0.78, -0.67, -0.54, -0.43]},\n",
    "    index = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9])\n",
    "\n",
    "perronModelC = pd.DataFrame({\n",
    "    '1%':[-4.38, -4.65, -4.78, -4.81, -4.90, -4.88, -4.75, -4.70, -4.41],\n",
    "    '2.5%':[-4.01, -4.32, -4.46, -4.48, -4.53, -4.49, -4.44, -4.31, -4.10],\n",
    "    '5%':[-3.75, -3.99, -4.17, -4.22, -4.24, -4.24, -4.18, -4.04, -3.80],\n",
    "    '10%':[-3.45, -3.66, -3.87, -3.95, -3.96, -3.95, -3.86, -3.69, -3.46],\n",
    "    '90%':[-1.44, -1.60, -1.78, -1.91, -1.96, -1.93, -1.81, -1.63, -1.44],\n",
    "    '95%':[-1.11, -1.27, -1.46, -1.62, -1.69, -1.63, -1.47, -1.29, -1.12],\n",
    "    '97.5%':[-0.82, -0.98, -1.15, -1.35, -1.43, -1.37, -1.17, -1.04, -0.80],\n",
    "    '99%':[-0.45, -0.67, -0.81, -1.04, -1.07, -1.08, -0.79, -0.64, -0.50]},\n",
    "    index = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874edbaf",
   "metadata": {},
   "source": [
    "# Cambio estructural y ra칤ces unitarias: fecha conocida\n",
    "\n",
    "\n",
    "\n",
    "## Cambio estructural y ra칤ces unitarias\n",
    "\n",
    "Cuando se realizan pruebas de ra칤z unitaria, debe tenerse cuidado si se sospecha que ha ocurrido un cambio estructural.\n",
    "\n",
    "Cuando hay cambios estructurales, los estad칤sticos Dickey-Fuller est치n sesgados hacia no rechazar la hip칩tesis de que hay ra칤z unitaria.\n",
    "\n",
    "\n",
    "\n",
    "## Ejemplos de cambios estructurales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14032568",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "np.random.seed(2020)\n",
    "\n",
    "T = 100\n",
    "data2 = pd.DataFrame({'t':np.arange(T), 'e':0.5*np.random.randn(T),'y0':0.0, 'y1':0.0})\n",
    "data2['DL'] = 3*(data2['t']>=T/2).astype(int)\n",
    "data2['DP'] = 5*(data2['t']==int(T/2)).astype(int)\n",
    "\n",
    "for t in range(1,T):\n",
    "    data2.loc[t,'y0'] = 0.5 * data2.loc[t-1,'y0'] + data2.loc[t,'e'] + data2.loc[t,'DL']\n",
    "    data2.loc[t,'y1'] = data2.loc[t-1,'y1'] + data2.loc[t,'e'] + data2.loc[t,'DP']\n",
    "\n",
    "fig, axs = plt.subplots(2,1, sharex=True)\n",
    "axs = data2[['y0', 'y1']].plot(subplots=True, ax=axs, legend=False)\n",
    "for ax in axs:\n",
    "    ax.axvline(T/2, ls=':', color='gray')\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "\n",
    "axs[0].set(title='$y_t = 0.5y_{t-1} + \\epsilon_t + D_L(50)$')    \n",
    "axs[1].set(title='$y_t = y_{t-1} + \\epsilon_t + D_P(50)$')    \n",
    "\n",
    "axs[0].annotate('A',[0.05,0.9], xycoords='axes fraction', size=26, color='red')\n",
    "axs[1].annotate('B',[0.05,0.9], xycoords='axes fraction', size=26, color='red')\n",
    "\n",
    "sns.regplot(x='t',y='y0', data=data2, ax=axs[0], color='C0')\n",
    "sns.regplot(x='t',y='y1', data=data2, ax=axs[1], color='C1');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a9853a",
   "metadata": {},
   "source": [
    "Los datos de la figura {badge}`A, badge-danger` fueron generados por\n",
    "\\begin{align*}\n",
    "y_t       &= 0.5y_{t-1} + \\epsilon_{t} + 3D_L(50)_t \\tag{AR(1) + cambio $\\mu$}\\\\\n",
    "D_L(50)_t &= \\mathrm{I}(t\\geq 50) \\tag{dummy de nivel}\n",
    "\\end{align*}\n",
    "\n",
    "La serie simulada parece tener una tendencia lineal.\n",
    "La manera apropiada de estimar este modelo es\n",
    "\\begin{equation*}\n",
    "y_t = \\beta_0 + \\beta_1y_{t-1} + \\delta D_L(50) + \\epsilon_{t}\n",
    "\\end{equation*}\n",
    "\n",
    "pero si estimamos\n",
    "\n",
    "\\begin{equation*}\n",
    "y_t = \\alpha_0 + \\alpha_1 t + \\epsilon_{t}\n",
    "\\end{equation*}\n",
    "\n",
    "el coeficiente $\\alpha_1$ tender칤a a ser positivo para capturar el salto en la serie.\n",
    "\n",
    "\n",
    "Suponga que por equivocaci칩n estimamos\n",
    "\\begin{equation*}\n",
    "y_t - y_{t-1} = c + \\gamma y_{t-1} + \\epsilon_{t}\n",
    "\\end{equation*}\n",
    "lo que ser칤a una caminata aleatoria con deriva si $\\gamma = 0$. Entonces:\n",
    "\\begin{equation*}\n",
    "y_t = y_0 + ct + \\sum_{i=i}^{t}\\epsilon_{i}\n",
    "\\end{equation*}\n",
    "\n",
    "Esta ecuaci칩n describe los datos de manera similar a como lo hace $y_t = \\alpha_0 + \\alpha_1 t + \\epsilon_{t}$, lo cual nos dice que la regresi칩n Dickey-Fuller sesgar칤a los resultados hacia $\\gamma = 0$, es decir, hacia no rechazar la presencia de una ra칤z unitaria.\n",
    "\n",
    "Perron (1989) demostr칩 este sesgo con simulaciones de Monte Carlo.\n",
    "\n",
    "\n",
    "Ahora bien, una serie con ra칤z unitaria tambi칠n puede presentar un cambio estructural, como en la figura {badge}`B, badge-danger`, generada por\n",
    "\\begin{align*}\n",
    "y_t &= y_{t-1} + \\epsilon_{t} + 5D_P(50)_t \\tag{RW + cambio $\\mu$}\\\\\n",
    "D_P(50)_t &= \\mathrm{I}(t = 50) \\tag{dummy de impulso}\n",
    "\\end{align*}\n",
    "\n",
    "Note que $D_P(t)$ es igual a 1 solo en el per칤odo $t$: cualquier cambio aditivo a una caminata aleatoria tiene un efecto permanente sobre el nivel de la serie.\n",
    "\n",
    "La serie simulada parece tener una tendencia lineal.\n",
    "De hecho, no es sencillo distinguirla de la figura **A** a simple vista.\n",
    "\n",
    "\n",
    "## 쮺칩mo saber entonces si una serie con cambio estructural tiene ra칤z unitaria?\n",
    "\n",
    "Una opci칩n, similar a lo que hace la prueba de Chow, es partir la muestra de datos en dos partes, y realizar pruebas de ra칤z unitaria en cada una por separado\n",
    "Lo malo de este procedimiento es que pierde muchos grados de libertad.\n",
    "Ser칤a preferible tener un test que utilice toda la muestra\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## 쮺aminata aleatoria o serie estacionaria alrededor de tendencia?\n",
    "\n",
    "\\textcite{Perron1989} desarrolla un procedimiento formal para detectar ra칤ces unitarias en presencia de un cambio estructural ocurrido en $t=\\tau$.\n",
    "\n",
    "Las hip칩tesis nula y alternativa son\n",
    "\\begin{align*}\n",
    "y_t &= \\alpha_0 + y_{t-1} + \\mu_1 D^P_t(\\tau) + \\epsilon_{t} \\tag{nula}\\\\\n",
    "y_t &= \\alpha_0 + \\alpha_2 t + \\mu_2 D^L_t(\\tau) + \\epsilon_{t} \\tag{alternativa}\n",
    "\\end{align*}\n",
    "\n",
    "Es decir, la hip칩tesis nula es que hay un solo salto en una caminata aleatoria en el per칤odo $\\tau$, la alternativa es que en esa misma fecha hay un solo salto en el intercepto de una serie estacionaria alrededor de tendencia.\n",
    "\n",
    "\n",
    "Observemos que\n",
    "\\begin{equation*}\n",
    "\\sum_{k=1}^{t}D_p(\\tau)_k = D_L(\\tau)_t\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d088264",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "T = 7\n",
    "data3 = pd.DataFrame(index=np.arange(T))\n",
    "data3['DL'] = (data3.index>=3).astype(int)\n",
    "data3['DP'] = (data3.index==3).astype(int)\n",
    "\n",
    "fig, axs = plt.subplots(2,1,figsize=[12,4], sharex=True)\n",
    "data3.plot.bar(subplots=True, width=0.05, ax=axs, legend=False)\n",
    "data3.plot(subplots=True, ls='', marker='o', ax=axs, legend=False)\n",
    "for ax in axs:\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['bottom'].set_linewidth(0.25)\n",
    "    ax.spines['left'].set_linewidth(0.25)\n",
    "    ax.set(yticks=[0,1], ylim=[-0.08, 1.08], title='')\n",
    "\n",
    "axs[1].set_xticks(np.arange(T))\n",
    "axs[1].set_xticklabels([f'$\\\\tau {tau:+d}$' if tau else '$\\\\tau$' for tau in range(-3,4)])\n",
    "axs[0].annotate('$D_L(\\\\tau)_t$', [0.5, 0.5], size=16, color=axs[0].lines[0].get_color())\n",
    "axs[1].annotate('$D_P(\\\\tau)_t$', [0.5, 0.5], size=16, color=axs[1].lines[0].get_color());"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0154a09a",
   "metadata": {},
   "source": [
    "Integrando la hip칩tesis nula\n",
    "\\begin{equation*}\n",
    "y_t = y_0 + \\alpha_0 t + \\mu_1D_L(\\tau)_t + \\sum_{k=0}^{t}\\epsilon_{k}\n",
    "\\end{equation*}\n",
    "vemos que es equivalente a la alternativa excepto por las perturbaciones.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Las pruebas de cambio estructural de Perron\n",
    "\n",
    "{{ empieza_test }} Las pruebas de cambio estructural de Perron {{ fin_titulo_test }}\n",
    "{{ test_inquietud }} 쮿ay ra칤ces unitarias en presencia de un cambio estructural en $t=\\tau$?\n",
    "{{ test_hipotesis }}\n",
    "\n",
    "{badge}`Modelo A: cambio de intercepto (crash), badge-success`\n",
    "\\begin{align*}\n",
    "y_t &= \\notationbrace{\\alpha_0 + \\mu_1 D^P_t}{intercepto} +  y_{t-1}  + \\epsilon_{t} \\tag{nula}\\\\\n",
    "y_t &= \\notationbrace{\\alpha_0 + \\mu_2 D_t^L}{intercepto} + \\alpha_2 t  + \\epsilon_{t} \\tag{alternativa}\n",
    "\\end{align*}\n",
    "\n",
    "{badge}`Modelo B: cambio de tendencia (changing growth), badge-success`\n",
    "\\begin{align*}\n",
    "y_t &= \\notationbrace{\\alpha_0 + \\mu_2 D^L_t}{intercepto} +  y_{t-1}  + \\epsilon_{t} \\tag{nula}\\\\\n",
    "y_t &= \\alpha_0 + \\notationbrace{\\alpha_2 t + \\mu_3 D^T_t}{tendencia} +  \\epsilon_{t} \\tag{alternativa}\n",
    "\\end{align*}\n",
    "donde $D^T_t(\\tau) = \\max(t-\\tau, 0)$\n",
    "\n",
    "{badge}`Modelo C: cambio de intercepto y de tendencia, badge-success`\n",
    "\\begin{align*}\n",
    "y_t &= \\notationbrace{\\alpha_0 + \\mu_1 D^P_t + \\mu_2 D^L_t}{intercepto} +  y_{t-1}  + \\epsilon_{t} \\tag{nula}\\\\\n",
    "y_t &= \\notationbrace{\\alpha_0 + \\mu_2 D_t^L}{intercepto} + \\notationbrace{\\alpha_2 t + \\mu_3 D^T_t}{tendencia} +  \\epsilon_{t} \\tag{alternativa}\n",
    "\\end{align*}\n",
    "{{ test_estadistico }}\n",
    "Para implementar la prueba de Perron se siguen 3 pasos:\n",
    "\n",
    "{badge}`Paso 1:, badge-dark` Se estima la regresi칩n correspondiente al modelo\n",
    "\\begin{align*}\n",
    "y_t &= \\alpha_0 + \\alert{\\alpha_1}y_{t-1} + \\alpha_2 t + \\mu_1 D_t^P + \\mu_2 D_t^L  +\\epsilon_{t} \\tag{A} \\\\\n",
    "y_t &= \\alpha_0 + \\alpha_2 t + \\mu_3 D_t^T  + \\tilde{y}_{t} \\qquad\\Rightarrow\n",
    "\\tilde{y}_t = \\alert{\\alpha_1}\\tilde{y}_{t-1} + \\epsilon_{t}  \\tag{B}  \\\\\n",
    "y_t &= \\alpha_0 + \\alert{\\alpha_1}y_{t-1} + \\alpha_2 t + \\mu_1 D_t^P + \\mu_2 D_t^L + \\mu_3 D_t^L  +\\epsilon_{t} \\tag{C}\\\\\n",
    "\\end{align*}\n",
    "\n",
    "{badge}`Paso 2:, badge-dark` Si los residuos de la regresi칩n est치n autocorrelacionados, se estima la regresi칩n ampliada, agregando $p$ rezagos del cambio en la variable:\n",
    "\\begin{align*}\n",
    "\\text{A y C} &:\\sum_{i=1}^{p}\\beta_i\\Delta y_{t-1}  &\n",
    "\\text{B} &:\\sum_{i=1}^{p}\\beta_i\\Delta \\tilde{y}_{t-1}\n",
    "\\end{align*}\n",
    "\n",
    "{badge}`Paso 3:,badge-dark` Se calcula el estad칤stico $t$ de la hip칩tesis $a_1=1$:\n",
    "\\begin{equation*}\n",
    "t_{\\alpha_1} = \\frac{\\hat{\\alpha_1}-1}{s.e.(\\alpha_1)}\n",
    "\\end{equation*}\n",
    "y se compara con el valor cr칤tico de Perron.\n",
    "{{ test_interpretacion }}\n",
    "Si el estad칤stico estimado es menor que el valor cr칤tico, se rechaza la hip칩tesis nula.\n",
    "\n",
    "El valor cr칤tico depende de la proporci칩n $\\lambda$ de observaciones que corresponden al periodo anterior al quiebre estructural.\n",
    "\n",
    "**Valores cr칤ticos de Perron**\n",
    "```{tabbed} Modelo A\n",
    "| 洧랝   |    1% |   2.5% |    5% |   10% |   90% |   95% |   97.5% |   99% |\n",
    "|----:|------:|-------:|------:|------:|------:|------:|--------:|------:|\n",
    "| 0.1 | -4.30 |  -3.93 | -3.68 | -3.40 | -1.38 | -1.09 |   -0.78 | -0.46 |\n",
    "| 0.2 | -4.39 |  -4.08 | -3.77 | -3.47 | -1.45 | -1.14 |   -0.90 | -0.54 |\n",
    "| 0.3 | -4.39 |  -4.03 | -3.76 | -3.46 | -1.43 | -1.13 |   -0.83 | -0.51 |\n",
    "| 0.4 | -4.34 |  -4.01 | -3.72 | -3.44 | -1.26 | -0.88 |   -0.55 | -0.21 |\n",
    "| 0.5 | -4.32 |  -4.01 | -3.76 | -3.46 | -1.17 | -0.79 |   -0.49 | -0.15 |\n",
    "| 0.6 | -4.45 |  -4.09 | -3.76 | -3.47 | -1.28 | -0.92 |   -0.60 | -0.26 |\n",
    "| 0.7 | -4.42 |  -4.07 | -3.80 | -3.51 | -1.42 | -1.10 |   -0.82 | -0.50 |\n",
    "| 0.8 | -4.33 |  -3.99 | -3.75 | -3.46 | -1.46 | -1.13 |   -0.89 | -0.57 |\n",
    "| 0.9 | -4.27 |  -3.97 | -3.69 | -3.38 | -1.37 | -1.04 |   -0.74 | -0.47 |\n",
    "```\n",
    "\n",
    "```{tabbed} Modelo B\n",
    "| 洧랝   |    1% |   2.5% |    5% |   10% |   90% |   95% |   97.5% |   99% |\n",
    "|----:|------:|-------:|------:|------:|------:|------:|--------:|------:|\n",
    "| 0.1 | -4.27 |  -3.94 | -3.65 | -3.36 | -1.35 | -1.04 |   -0.78 | -0.40 |\n",
    "| 0.2 | -4.41 |  -4.08 | -3.80 | -3.49 | -1.48 | -1.18 |   -0.87 | -0.52 |\n",
    "| 0.3 | -4.51 |  -4.17 | -3.87 | -3.58 | -1.59 | -1.27 |   -0.97 | -0.69 |\n",
    "| 0.4 | -4.55 |  -4.20 | -3.94 | -3.66 | -1.69 | -1.37 |   -1.11 | -0.75 |\n",
    "| 0.5 | -4.56 |  -4.26 | -3.96 | -3.68 | -1.74 | -1.40 |   -1.18 | -0.82 |\n",
    "| 0.6 | -4.57 |  -4.20 | -3.95 | -3.66 | -1.71 | -1.36 |   -1.11 | -0.78 |\n",
    "| 0.7 | -4.51 |  -4.13 | -3.85 | -3.57 | -1.61 | -1.28 |   -0.97 | -0.67 |\n",
    "| 0.8 | -4.38 |  -4.07 | -3.82 | -3.50 | -1.49 | -1.16 |   -0.87 | -0.54 |\n",
    "| 0.9 | -4.26 |  -3.96 | -3.68 | -3.35 | -1.34 | -1.04 |   -0.77 | -0.43 |\n",
    "```\n",
    "\n",
    "```{tabbed} Modelo C\n",
    "| 洧랝   |    1% |   2.5% |    5% |   10% |   90% |   95% |   97.5% |   99% |\n",
    "|----:|------:|-------:|------:|------:|------:|------:|--------:|------:|\n",
    "| 0.1 | -4.38 |  -4.01 | -3.75 | -3.45 | -1.44 | -1.11 |   -0.82 | -0.45 |\n",
    "| 0.2 | -4.65 |  -4.32 | -3.99 | -3.66 | -1.60 | -1.27 |   -0.98 | -0.67 |\n",
    "| 0.3 | -4.78 |  -4.46 | -4.17 | -3.87 | -1.78 | -1.46 |   -1.15 | -0.81 |\n",
    "| 0.4 | -4.81 |  -4.48 | -4.22 | -3.95 | -1.91 | -1.62 |   -1.35 | -1.04 |\n",
    "| 0.5 | -4.90 |  -4.53 | -4.24 | -3.96 | -1.96 | -1.69 |   -1.43 | -1.07 |\n",
    "| 0.6 | -4.88 |  -4.49 | -4.24 | -3.95 | -1.93 | -1.63 |   -1.37 | -1.08 |\n",
    "| 0.7 | -4.75 |  -4.44 | -4.18 | -3.86 | -1.81 | -1.47 |   -1.17 | -0.79 |\n",
    "| 0.8 | -4.70 |  -4.31 | -4.04 | -3.69 | -1.63 | -1.29 |   -1.04 | -0.64 |\n",
    "| 0.9 | -4.41 |  -4.10 | -3.80 | -3.46 | -1.44 | -1.12 |   -0.80 | -0.50 |\n",
    "```\n",
    "Fuente: \\textcite{Perron1989}\n",
    "{{ termina_test }}\n",
    "\n",
    "\n",
    "\n",
    "{{ empieza_ejemplo }} Pruebas de cambio estructural {{ fin_titulo_ejemplo }}\n",
    "\n",
    "Perron analiza los datos de Nelson y Plosser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a6a39c",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "pd.options.plotting.backend = \"plotly\"\n",
    "\n",
    "NP = pd.read_stata('datos/NelsonPlosserData.dta', index_col='year')\n",
    "NP.index = NP.index.year\n",
    "\n",
    "# modelo de salarios nominales\n",
    "lwg = NP[['lwg']].dropna()\n",
    "lwg['DL'] = (lwg.index > 1929).astype(int)\n",
    "lwg['DP'] = (lwg.index == 1930).astype(int)\n",
    "lwg['t'] = np.arange(lwg.shape[0])\n",
    "lwg['Ly'] = lwg['lwg'].shift(1)\n",
    "model1_lwg = ols('lwg~ DL + DP + t + Ly', lwg).fit()\n",
    "model2_lwg = ols('lwg~ DL + t ', lwg).fit()\n",
    "\n",
    "lwg['Ajuste'] = model2_lwg.fittedvalues\n",
    "\n",
    "lwg[['lwg', 'Ajuste']].plot()\n",
    "\n",
    "#title='Salarios nominales'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7735a05",
   "metadata": {},
   "source": [
    "Al estimar el modelo A\n",
    "\\begin{equation*}\n",
    "y_t = \\alpha_0 + \\alpha_1y_{t-1} + \\alpha_2 t + \\mu_1 D_t^P + \\mu_2 D_t^L +\\sum_{i=1}^{p}\\beta_i\\Delta y_{t-1}  +\\epsilon_{t}\n",
    "\\end{equation*}\n",
    "\n",
    "encuentran"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c333a06a",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "def Perron_testA(serie, k=8):\n",
    "    dta = NP[[serie]].dropna()\n",
    "    dta.rename(columns={serie:'y'}, inplace=True)\n",
    "    dta['DL'] = (dta.index>1929).astype(int)\n",
    "    dta['DP'] = (dta.index==1930).astype(int)\n",
    "    dta['t'] = np.arange(dta.shape[0])\n",
    "    dta['Ly'] = dta['y'].shift(1)\n",
    "    dta['Dy'] = dta['y'].diff(1)\n",
    "    for j in range(1, k+1):\n",
    "        dta[f'D{j}y'] = dta['Dy'].shift(j)\n",
    "\n",
    "    lags = '+'.join(dta.columns[-k:])\n",
    "\n",
    "    modelo = ols('y ~ DL + DP + t + Ly + '+ lags, dta).fit()\n",
    "    tval = ((modelo.params - 1)/modelo.bse).round(2)['Ly']\n",
    "    lda = 1-dta['DL'].mean()\n",
    "    crit = perronModelA.loc[np.round(lda,1)]\n",
    "\n",
    "    return {'洧랝': np.round(lda,2), 't': tval, '1%':crit['1%'],'5%':crit['5%'],'10%':crit['10%']}\n",
    "\n",
    "variables = {'lrgnp':'Real GNP',\n",
    "           'lgnp':'Nominal GNP',\n",
    "           'lpcrgnp':'Real per capita GNP',\n",
    "           'lip':'Industrial production',\n",
    "           'lemp':'Employment',\n",
    "           'lun':'Unemployment rate',\n",
    "           'lprgnp':'GNP deflator',\n",
    "           'lcpi':'Consumer prices',\n",
    "           'lwg':'Wages',\n",
    "           'lrwg':'Real wages',\n",
    "           'lm':'Money stock',\n",
    "           'lvel':'Velocity',\n",
    "           'bnd':'Bond yield',\n",
    "           'lsp500':'Common stock prices'}\n",
    "\n",
    "seriesA = ['lrgnp', 'lgnp', 'lpcrgnp', 'lip', 'lemp', 'lprgnp', 'lcpi', 'lwg', 'lm']\n",
    "lags = [8,8,7,8,7,5,2,7,6]\n",
    "\n",
    "temp = pd.DataFrame([Perron_testA(ser, k) for ser, k in zip(seriesA, lags)], index=seriesA)\n",
    "temp.rename(index=variables).to_latex('perron-nelson-plosser.tex', escape=False)\n",
    "\n",
    "temp.rename(index=variables)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491371bb",
   "metadata": {},
   "source": [
    "{{ termina_ejemplo }}"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "md:myst",
   "text_representation": {
    "extension": ".md",
    "format_name": "myst"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "source_map": [
   30,
   37,
   81,
   98,
   126,
   203,
   224,
   340,
   361,
   372,
   419
  ],
  "substitutions": {
   "empieza_ejemplo": "<div class=\"ejemplo\">\n<div class=\"ejemplo-titulo\"><b>Ejemplo: &nbsp;\n",
   "empieza_test": "<div class=\"test\">\n<div class=\"test-titulo\">\n",
   "fin_titulo_ejemplo": "</b></div>",
   "fin_titulo_test": "</div>",
   "termina_ejemplo": "</div>",
   "termina_test": "</div>",
   "test_estadistico": "<br><hr><i class=\"fas fa-calculator test-simbolo\"></i>\n",
   "test_hipotesis": "<br><hr><i class=\"fas fa-heading test-simbolo\"></i>\n",
   "test_inquietud": "<i class=\"fas fa-question test-simbolo\"></i>\n",
   "test_interpretacion": "<br><hr><i class=\"far fa-lightbulb test-simbolo\"></i>"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}